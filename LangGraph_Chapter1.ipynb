{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangGraph, developed by LangChain, is a framework that enables the construction of stateful, graph-based workflows for AI-driven applications.\n",
    "\n",
    "LangGraph facilitates the creation of structured, modular, and scalable AI workflows by leveraging graph-based processing. This approach provides greater control, adaptability, and efficiency compared to traditional linear pipelines.\n",
    "Core Concepts of LangGraph\n",
    "LangGraph introduces a graph-based execution model where an AI-driven workflow is represented as a graph of nodes and edges. The key components include:\n",
    "\n",
    "1. State\n",
    "The state represents the shared context across different nodes.\n",
    "It can be implemented using Python types such as TypedDict or Pydantic BaseModel.\n",
    "State allows information to persist across different steps in the workflow.\n",
    "2. Nodes\n",
    "Nodes are functions that perform specific tasks within the graph.\n",
    "Each node receives state as input, processes it, and returns an updated state.\n",
    "A node can represent a variety of AI operations, including LLM interactions, data transformations, or API calls.\n",
    "3. Edges\n",
    "Edges define execution flow by determining how nodes transition between different states.\n",
    "They can be simple linear connections or conditional branches that introduce decision-making capabilities.\n",
    "LangGraph provides the flexibility to model dynamic workflows, making it ideal for multi-agent applications, conversational AI, and structured content generation.\n",
    "\n",
    "Graph vs. StateGraph in LangGraph\n",
    "While graphs in LangGraph define execution flows, StateGraph is an enhanced version that incorporates state management.\n",
    "\n",
    "Graph vs. StateGraph in LangGraph: Understanding the Key Differences\n",
    "LangGraph provides two primary execution models: Graph and StateGraph, each serving different use cases based on workflow complexity and state management requirements.\n",
    "\n",
    "A Graph in LangGraph is a straightforward execution structure where nodes are connected by edges, defining a sequential or conditional flow of execution. However, it does not inherently maintain a shared state, meaning each node functions independently, processing inputs and producing outputs without persistent data across executions. This makes it ideal for simple routing, static workflows, and task sequencing where context retention is not required.\n",
    "\n",
    "On the other hand, StateGraph extends the Graph model by incorporating stateful execution, where nodes can modify and retain a shared state throughout the workflow. This allows for dynamic decision-making, enabling the workflow to adapt based on intermediate results. StateGraph is particularly useful for complex AI-driven applications, such as multi-turn conversations, iterative LLM processing, and multi-agent coordination, where maintaining context is crucial.\n",
    "\n",
    "In summary, Graph is suited for simpler, stateless workflows, while StateGraph is essential for stateful, multi-step processes requiring context retention and real-time state updates. Choosing between them depends on whether the workflow requires persistent data flow across different nodes or can function independently without shared memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"mistral\", base_url=\"http://localhost:11434\")\n",
    "\n",
    "def generate_article(input):\n",
    "    prompt = f\"Write an article on the given topic: {input}\"\n",
    "    response = llm.invoke(prompt).content\n",
    "    return {\"Article\": response}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary(article):\n",
    "    prompt = f\"Summarize the article {article} in 5 points\"\n",
    "    response = llm.invoke(prompt).content\n",
    "    return {\"Summary\": response}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import Graph\n",
    "graph = Graph()\n",
    "graph.add_node(\"generate_article\", generate_article)\n",
    "graph.add_node(\"create_summary\", create_summary)\n",
    "\n",
    "graph.add_edge(\"generate_article\", \"create_summary\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.set_entry_point(\"generate_article\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.set_finish_point(\"create_summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(app.invoke(\"LangChain\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=\"LangChain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for output in app.stream(input):\n",
    "    for key,value in output.items():\n",
    "        print(f\"Output from {key}\")\n",
    "        print(\"_______\")\n",
    "        print(value)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraphenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
